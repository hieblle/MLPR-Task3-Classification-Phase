# MLPR-Task3-Classification-Phase

1. How was the cross-validation split done, and why? Decide how to split
up the data into folds, based on what you know about the data. Avoid
information leakage from the training into the validation set!

2. Which subset of features was selected or which preprocessing was
applied, and why?

3. What would be an appropriate evaluation criterion to compare
parameter settings and algorithms?

4. Apply at least least four different learning algorithms (from different
major groups: Support Vector Machines, Neural Networks, Nearest
Neighbor Classifiers, Naive Bayes, Decision Trees, Generalized Linear
Models, Linear and Quadratic Discriminant Analysis... maybe also an
"ensemble method" such as a Random Forest). For each algorithm
perform a systematic evaluation of different parameter settings, and
focus on two aspects:
4.1 Investigate whether overfitting occurs, and to what extent (and
which parameters control the overfitting behavior).
4.2 How do classification results change when varying the
parameters?

5. BONUS: Train at least one classifier on predicting (a relevant subset of)
the 9 GEMS and 5 GEMMES features (i.e., treat each of these features
as independent binary classification problems).
